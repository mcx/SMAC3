{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SVM with EIPS as acquisition functions\n\nAn example to optimize a simple SVM on the IRIS-benchmark with EIPS (EI per seconds)\nacquisition function. Since EIPS requires two types of objections: EI values and the predicted\ntime used for the configurations. We need to fit the data\nwith a multi-objective model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n\nlogging.basicConfig(level=logging.INFO)\n\nimport numpy as np\nfrom ConfigSpace.hyperparameters import (\n    CategoricalHyperparameter,\n    UniformFloatHyperparameter,\n)\nfrom sklearn import datasets, svm\nfrom sklearn.model_selection import cross_val_score\n\nfrom smac.configspace import ConfigurationSpace\nfrom smac.epm.uncorrelated_mo_rf_with_instances import (\n    UncorrelatedMultiObjectiveRandomForestWithInstances,\n)\nfrom smac.facade.smac_ac_facade import SMAC4AC\n\n# EIPS related\nfrom smac.optimizer.acquisition import EIPS\nfrom smac.runhistory.runhistory2epm import RunHistory2EPM4EIPS\n\n# Import SMAC-utilities\nfrom smac.scenario.scenario import Scenario\n\n__copyright__ = \"Copyright 2021, AutoML.org Freiburg-Hannover\"\n__license__ = \"3-clause BSD\"\n\niris = datasets.load_iris()\n\n\n# Target Algorithm\ndef svm_from_cfg(cfg):\n    \"\"\"Creates a SVM based on a configuration and evaluates it on the\n    iris-dataset using cross-validation. Note here random seed is fixed\n\n    Parameters:\n    -----------\n    cfg: Configuration (ConfigSpace.ConfigurationSpace.Configuration)\n        Configuration containing the parameters.\n        Configurations are indexable!\n\n    Returns:\n    --------\n    A crossvalidated mean score for the svm on the loaded data-set.\n    \"\"\"\n    # For deactivated parameters, the configuration stores None-values.\n    # This is not accepted by the SVM, so we remove them.\n    cfg = {k: cfg[k] for k in cfg if cfg[k]}\n    # And for gamma, we set it to a fixed value or to \"auto\" (if used)\n    if \"gamma\" in cfg:\n        cfg[\"gamma\"] = cfg[\"gamma_value\"] if cfg[\"gamma\"] == \"value\" else \"auto\"\n        cfg.pop(\"gamma_value\", None)  # Remove \"gamma_value\"\n\n    clf = svm.SVC(**cfg, random_state=42)\n\n    scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n    return 1 - np.mean(scores)  # Minimize!\n\n\nif __name__ == \"__main__\":\n    # Build Configuration Space which defines all parameters and their ranges\n    cs = ConfigurationSpace()\n\n    # We define a few possible types of SVM-kernels and add them as \"kernel\" to our cs\n    kernel = CategoricalHyperparameter(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"], default_value=\"poly\")\n    cs.add_hyperparameter(kernel)\n\n    # There are some hyperparameters shared by all kernels\n    C = UniformFloatHyperparameter(\"C\", 0.001, 1000.0, default_value=1.0, log=True)\n    shrinking = CategoricalHyperparameter(\"shrinking\", [True, False], default_value=True)\n    cs.add_hyperparameters([C, shrinking])\n\n    # Scenario object\n    scenario = Scenario(\n        {\n            \"run_obj\": \"quality\",  # we optimize quality (alternatively runtime)\n            \"runcount-limit\": 50,  # max. number of function evaluations\n            \"cs\": cs,  # configuration space\n            \"deterministic\": True,\n        }\n    )\n\n    # Example call of the function\n    # It returns: Status, Cost, Runtime, Additional Infos\n    def_value = svm_from_cfg(cs.get_default_configuration())\n    print(\"Default Value: %.2f\" % def_value)\n\n    # Optimize, using a SMAC-object\n    print(\"Optimizing! Depending on your machine, this might take a few minutes.\")\n\n    # Besides the kwargs used for initializing UncorrelatedMultiObjectiveRandomForestWithInstances,\n    # we also need kwargs for initializing the model insides UncorrelatedMultiObjectiveModel\n    model_kwargs = {\"target_names\": [\"loss\", \"time\"], \"model_kwargs\": {\"seed\": 1}}\n    smac = SMAC4AC(\n        scenario=scenario,\n        model=UncorrelatedMultiObjectiveRandomForestWithInstances,\n        rng=np.random.RandomState(42),\n        model_kwargs=model_kwargs,\n        tae_runner=svm_from_cfg,\n        acquisition_function=EIPS,\n        runhistory2epm=RunHistory2EPM4EIPS,\n    )\n\n    incumbent = smac.optimize()\n\n    inc_value = svm_from_cfg(incumbent)\n    print(\"Optimized Value: %.2f\" % (inc_value))\n\n    # We can also validate our results (though this makes a lot more sense with instances)\n    smac.validate(\n        config_mode=\"inc\",  # We can choose which configurations to evaluate\n        # instance_mode='train+test',  # Defines what instances to validate\n        repetitions=100,  # Ignored, unless you set \"deterministic\" to \"false\" in line 95\n        n_jobs=1,\n    )  # How many cores to use in parallel for optimization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}