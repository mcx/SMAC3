{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SVM with Cross-Validation\n\nAn example to optimize a simple SVM on the IRIS-benchmark. SMAC4HPO is designed\nfor hyperparameter optimization (HPO) problems and uses an RF as its surrogate model.\nIt is able to scale to higher evaluation budgets and higher number of\ndimensions. Also, you can use mixed data types as well as conditional hyperparameters.\n\nSMAC4HPO by default only contains single fidelity approach. Therefore, only the configuration is\nprocessed by the :term:`TAE`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\n\nlogging.basicConfig(level=logging.INFO)\n\nimport numpy as np\nfrom ConfigSpace.conditions import InCondition\nfrom ConfigSpace.hyperparameters import (\n    CategoricalHyperparameter,\n    UniformFloatHyperparameter,\n    UniformIntegerHyperparameter,\n)\nfrom sklearn import datasets, svm\nfrom sklearn.model_selection import cross_val_score\n\nfrom smac.configspace import ConfigurationSpace\nfrom smac.facade.smac_hpo_facade import SMAC4HPO\nfrom smac.scenario.scenario import Scenario\n\n__copyright__ = \"Copyright 2021, AutoML.org Freiburg-Hannover\"\n__license__ = \"3-clause BSD\"\n\n\n# We load the iris-dataset (a widely used benchmark)\niris = datasets.load_iris()\n\n\ndef svm_from_cfg(cfg):\n    \"\"\"Creates a SVM based on a configuration and evaluates it on the\n    iris-dataset using cross-validation. Note here random seed is fixed\n\n    Parameters:\n    -----------\n    cfg: Configuration (ConfigSpace.ConfigurationSpace.Configuration)\n        Configuration containing the parameters.\n        Configurations are indexable!\n\n    Returns:\n    --------\n    A crossvalidated mean score for the svm on the loaded data-set.\n    \"\"\"\n    # For deactivated parameters, the configuration stores None-values.\n    # This is not accepted by the SVM, so we remove them.\n    cfg = {k: cfg[k] for k in cfg if cfg[k]}\n    # And for gamma, we set it to a fixed value or to \"auto\" (if used)\n    if \"gamma\" in cfg:\n        cfg[\"gamma\"] = cfg[\"gamma_value\"] if cfg[\"gamma\"] == \"value\" else \"auto\"\n        cfg.pop(\"gamma_value\", None)  # Remove \"gamma_value\"\n\n    clf = svm.SVC(**cfg, random_state=42)\n\n    scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n    return 1 - np.mean(scores)  # Minimize!\n\n\nif __name__ == \"__main__\":\n    # Build Configuration Space which defines all parameters and their ranges\n    cs = ConfigurationSpace()\n\n    # We define a few possible types of SVM-kernels and add them as \"kernel\" to our cs\n    kernel = CategoricalHyperparameter(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"], default_value=\"poly\")\n    cs.add_hyperparameter(kernel)\n\n    # There are some hyperparameters shared by all kernels\n    C = UniformFloatHyperparameter(\"C\", 0.001, 1000.0, default_value=1.0, log=True)\n    shrinking = CategoricalHyperparameter(\"shrinking\", [True, False], default_value=True)\n    cs.add_hyperparameters([C, shrinking])\n\n    # Others are kernel-specific, so we can add conditions to limit the searchspace\n    degree = UniformIntegerHyperparameter(\"degree\", 1, 5, default_value=3)  # Only used by kernel poly\n    coef0 = UniformFloatHyperparameter(\"coef0\", 0.0, 10.0, default_value=0.0)  # poly, sigmoid\n    cs.add_hyperparameters([degree, coef0])\n\n    use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n    use_coef0 = InCondition(child=coef0, parent=kernel, values=[\"poly\", \"sigmoid\"])\n    cs.add_conditions([use_degree, use_coef0])\n\n    # This also works for parameters that are a mix of categorical and values\n    # from a range of numbers\n    # For example, gamma can be either \"auto\" or a fixed float\n    gamma = CategoricalHyperparameter(\"gamma\", [\"auto\", \"value\"], default_value=\"auto\")  # only rbf, poly, sigmoid\n    gamma_value = UniformFloatHyperparameter(\"gamma_value\", 0.0001, 8, default_value=1, log=True)\n    cs.add_hyperparameters([gamma, gamma_value])\n    # We only activate gamma_value if gamma is set to \"value\"\n    cs.add_condition(InCondition(child=gamma_value, parent=gamma, values=[\"value\"]))\n    # And again we can restrict the use of gamma in general to the choice of the kernel\n    cs.add_condition(InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"]))\n\n    # Scenario object\n    scenario = Scenario(\n        {\n            \"run_obj\": \"quality\",  # we optimize quality (alternatively runtime)\n            \"runcount-limit\": 50,  # max. number of function evaluations\n            \"cs\": cs,  # configuration space\n            \"deterministic\": True,\n        }\n    )\n\n    # Example call of the function\n    # It returns: Status, Cost, Runtime, Additional Infos\n    def_value = svm_from_cfg(cs.get_default_configuration())\n    print(\"Default Value: %.2f\" % (def_value))\n\n    # Optimize, using a SMAC-object\n    print(\"Optimizing! Depending on your machine, this might take a few minutes.\")\n    smac = SMAC4HPO(scenario=scenario, rng=np.random.RandomState(42), tae_runner=svm_from_cfg)\n\n    incumbent = smac.optimize()\n\n    inc_value = svm_from_cfg(incumbent)\n    print(\"Optimized Value: %.2f\" % (inc_value))\n\n    # We can also validate our results (though this makes a lot more sense with instances)\n    smac.validate(\n        config_mode=\"inc\",  # We can choose which configurations to evaluate\n        # instance_mode='train+test',  # Defines what instances to validate\n        repetitions=100,  # Ignored, unless you set \"deterministic\" to \"false\" in line 95\n        n_jobs=1,\n    )  # How many cores to use in parallel for optimization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}