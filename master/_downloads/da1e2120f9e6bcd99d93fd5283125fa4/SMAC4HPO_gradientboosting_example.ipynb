{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Optimizing GradientBoosting with SMAC4HPO\n\n\nAn example for the usage of SMAC within Python.\nWe optimize a GradientBoosting on an artificially created binary classification dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nlogging.basicConfig(level=logging.INFO)\n\nimport numpy as np\n\nfrom ConfigSpace.hyperparameters import UniformFloatHyperparameter, UniformIntegerHyperparameter\n\nfrom sklearn.datasets import make_hastie_10_2\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\n\nfrom smac.configspace import ConfigurationSpace\nfrom smac.facade.smac_hpo_facade import SMAC4HPO\nfrom smac.scenario.scenario import Scenario\n\n__copyright__ = \"Copyright 2021, AutoML.org Freiburg-Hannover\"\n__license__ = \"3-clause BSD\"\n\n\n# load data and split it into training and test dataset\nX, y = make_hastie_10_2(random_state=0)\nX_train, X_test = X[:8400], X[8400:]\ny_train, y_test = y[:8400], y[8400:]\n\n\n# Gradient Boosting scored with cross validation\ndef xgboost_from_cfg(cfg):\n    clf = GradientBoostingClassifier(**cfg, random_state=0).fit(X_train, y_train)\n    scores = cross_val_score(clf, X_train, y_train)\n    return 1 - np.mean(scores)\n\n\nif __name__ == \"__main__\":\n    # creating a Configuration Space with every parameter over which SMAC is going to optimize\n    cs = ConfigurationSpace()\n\n    max_depth = UniformIntegerHyperparameter(\"max_depth\", 1, 10, default_value=3)\n    cs.add_hyperparameter(max_depth)\n\n    learning_rate = UniformFloatHyperparameter(\"learning_rate\", 0.01, 1.0, default_value=1.0, log=True)\n    cs.add_hyperparameter(learning_rate)\n\n    min_samples_split = UniformFloatHyperparameter(\"min_samples_split\", 0.01, 1.0, default_value=0.1, log=True)\n    max_features = UniformIntegerHyperparameter(\"max_features\", 2, 10, default_value=4)\n    cs.add_hyperparameters([min_samples_split, max_features])\n\n    subsample = UniformFloatHyperparameter(\"subsample\", 0.5, 1, default_value=0.8)\n    cs.add_hyperparameter(subsample)\n\n    print(\"default cross validation score: %.2f\" % (xgboost_from_cfg(cs.get_default_configuration())))\n    cfg = cs.get_default_configuration()\n    clf = GradientBoostingClassifier(**cfg, random_state=0).fit(X_train, y_train)\n    def_test_score = 1 - clf.score(X_test, y_test)\n    print(\"default test score: %.2f\" % def_test_score)\n\n    # scenario object\n    scenario = Scenario({\"run_obj\": \"quality\",\n                        \"runcount-limit\": 100,\n                         \"cs\": cs,\n                         \"deterministic\": \"true\",\n                         \"wallclock_limit\": 120\n                         })\n\n    smac = SMAC4HPO(scenario=scenario, rng=np.random.RandomState(0), tae_runner=xgboost_from_cfg)\n\n    # the optimization process is called\n    incumbent = smac.optimize()\n\n    # a classifier is trained with the hyperparameters returned from the optimizer\n    clf_incumbent = GradientBoostingClassifier(**incumbent, random_state=0).fit(X_train, y_train)\n\n    # evaluated on test\n    inc_value_1 = 1 - clf_incumbent.score(X_test, y_test)\n    print(\"Score on test set: %.2f\" % (inc_value_1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}